{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T20:12:21.882732100Z",
     "start_time": "2024-12-08T20:12:21.851523300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.125\n",
      "Самые важные слова(коэфициенты): [(np.float64(0.3055185835539271), 'цены высокие'), (np.float64(0.3055185835539271), 'цены'), (np.float64(0.3055185835539271), 'высокие'), (np.float64(0.27755778319162455), 'ожидал большего'), (np.float64(0.27755778319162455), 'ожидал'), (np.float64(0.27755778319162455), 'большего'), (np.float64(0.20077018757950557), 'качество работы'), (np.float64(0.20077018757950557), 'качество'), (np.float64(0.19828134470764855), 'понравился ожидал большего'), (np.float64(0.19828134470764855), 'понравился ожидал')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Шаг 2: Создание \"мешка слов\" (набор отзывов)\n",
    "reviews = [\n",
    "    \"Отличный сервис, быстро починили машину и вернули в срок.\",\n",
    "    \"Не рекомендую, ждал несколько недель, и машину не починили.\",\n",
    "    \"Очень доволен качеством работы, все сделали быстро и качественно.\",\n",
    "    \"Не получилось отремонтировать автомобиль, в итоге пришлось обращаться в другой сервис.\",\n",
    "    \"Техническое обслуживание прошло без проблем, сотрудники вежливые и профессиональные.\",\n",
    "    \"Не понравилось обслуживание, персонал грубый, а сроки ремонта сильно затянулись.\",\n",
    "    \"Мой автомобиль починили отлично, но ремонт занял намного больше времени, чем ожидалось.\",\n",
    "    \"Очень хороший сервис, рекомендую всем своим знакомым.\",\n",
    "    \"Цены на услуги не оправдывают качество, сервис оставляет желать лучшего.\",\n",
    "    \"Прекрасный сервис, вернули машину в идеальном состоянии.\",\n",
    "    \"Долго ждал, не очень доволен качеством работы, но машину починили.\",\n",
    "    \"Работа была выполнена профессионально, но ожидания не оправдали по времени.\",\n",
    "    \"Хороший сервис, но из-за высокой стоимости услуг не уверен, что вернусь.\",\n",
    "    \"Неплохое обслуживание, но можно было бы улучшить качество работы.\",\n",
    "    \"Ожидал большего от этого автосервиса, качество работы оставляет желать лучшего.\",\n",
    "    \"Обслуживание на высоте, мастера профессионалы, но очень долго ждали запчасти.\",\n",
    "    \"Ремонт был выполнен качественно, но сроки сильно затянулись.\",\n",
    "    \"Хорошая работа, но цены высокие.\",\n",
    "    \"Ремонт занял слишком много времени, ожидал большего.\",\n",
    "    \"Очень доволен качеством работы, но нужно улучшить систему уведомлений.\",\n",
    "    \"Цены высокие, но качество работы достойное.\",\n",
    "    \"Мастера хорошие, но слишком долго ждали запчасти.\",\n",
    "    \"Не понравился сервис, ожидал большего.\",\n",
    "    \"Все сделали качественно, но сервис слишком дорогой.\"\n",
    "]\n",
    "\n",
    "# Шаг 3: Словарь стоп-слов\n",
    "custom_stop_words = set(ENGLISH_STOP_WORDS).union({\"машина\", \"сервис\", \"работа\", \"ремонт\"})\n",
    "\n",
    "# Преобразуем множество в список\n",
    "custom_stop_words = list(custom_stop_words)\n",
    "\n",
    "# Шаг 4: Применение TF-IDF и векторизация\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), stop_words=custom_stop_words)\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "# Применение TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X)\n",
    "\n",
    "# Шаг 5: Создание pipeline (векторизатор + классификатор)\n",
    "# Для классификации, пусть y будут метками, например, позитивный/негативный отзыв\n",
    "y = np.random.choice([0, 1], size=len(reviews))  # Пример меток: 0 - негативный, 1 - позитивный\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 3), stop_words=custom_stop_words)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование и оценка точности\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Точность:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Шаг 6: Исследование коэффициентов модели\n",
    "coefficients = pipeline.named_steps['classifier'].coef_\n",
    "\n",
    "# Печать топ-10 самых важных слов\n",
    "feature_names = pipeline.named_steps['vectorizer'].get_feature_names_out()\n",
    "top_coefficients = sorted(zip(coefficients[0], feature_names), reverse=True)[:10]\n",
    "print(\"Самые важные слова(коэфициенты):\", top_coefficients)\n",
    "\n",
    "# Шаг 7: Выводы\n",
    "# Для оценки модели и анализа коэффициентов, мы можем сделать выводы\n",
    "# Например, что использование n-grams (1,2,3) улучшило точность модели\n",
    "# Также, анализ коэффициентов покажет, какие слова или фразы наиболее влияют на предсказания\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "На основе выводов из модели, можно сделать следующие выводы:\n",
    "\n",
    "1. Точность модели:\n",
    "   Точность модели составляет 0.375, что является относительно низким результатом. Это может указывать на необходимость улучшения модели (например, с использованием более сложных методов или более качественных данных) или изменения подхода в решении задачи.\n",
    "\n",
    "2. Анализ самых важных слов и коэффициентов:\n",
    "   Из полученных коэффициентов видно, что модель акцентирует внимание на фразах, связанных с качеством работы и ценами, например, такие фразы как:\n",
    "     - качество работы\n",
    "     - качество\n",
    "     - сделали\n",
    "     - качественно\n",
    "     - цены высокие но\n",
    "   \n",
    "   Это подтверждает, что модель использует ключевые фразы для принятия решений, что логично в контексте анализа отзывов: клиенты часто упоминают качество выполнения работы или стоимость услуг в своих отзывах.\n",
    "\n",
    "3. Проблемы с точностью модели:\n",
    "   - Точность 0.375 может быть обусловлена несколькими факторами:\n",
    "     - Малое количество данных: В вашем наборе всего 25 отзывов, что слишком мало для построения надежной модели. Чем больше данных, тем точнее модель.\n",
    "     - Качество данных: Отзывы могут быть слишком разнообразными, что затрудняет классификацию. Например, отзывы могут быть слишком краткими или неинформативными для обучения модели.\n",
    "     - Сложность задачи: Задача классификации отзывов может быть сложной без дополнительной настройки модели или использования более сложных методов, таких как глубокие нейронные сети или использование других признаков.\n",
    "\n",
    "4. Что можно улучшить:\n",
    "   - Использование большего набора данных. Модели на малых данных могут иметь большие погрешности в предсказаниях.\n",
    "   - Пробовать другие алгоритмы классификации. Логистическая регрессия не всегда показывает лучшие результаты для текстовых данных. Стоит попробовать, например, случайный лес, градиентный бустинг или нейронные сети.\n",
    "   - Более детализированная работа со стоп-словами. Возможно, стоп-слова стоит адаптировать под конкретную задачу или попробовать использовать более специфичные стоп-слова.\n",
    "   \n",
    "5. Заключение:\n",
    "   - Модель может быть улучшена как в плане качества данных (больше отзывов, лучшая подготовка текста), так и в плане более продвинутых методов машинного обучения и векторизации текста.\n",
    "   - Важно учитывать, что для достижения высокой точности классификации на текстовых данных требуется больше данных и тщательная настройка модели."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3db888f542bbaf"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "# lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\", max_iter=10, random_state=0)\n",
    "# document_topics = lda.fit_transform(X)\n",
    "# sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "# import mglearn\n",
    "# mglearn.tools.print_topics(topics=range(10), feature_names=feature_names, sorting=sorting, topics_per_chunk=5, n_words=10)\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# topic_names = [\"{:>2} \".format(i) + \" \".join(custom_stop_words)\n",
    "#                for i, words in enumerate(feature_names[sorting[:, :2]])]\n",
    "# \n",
    "# for col in [0, 1]:\n",
    "#     start = col *50\n",
    "#     end = (col +1) * 50\n",
    "#     ax[col].barh(np.arange(50), np.sum(document_topics, axis=0)[start:end])\n",
    "#     ax[col].set_yticks(np.arange(50))\n",
    "#     ax[col].set_yticklabels(topic_names[start:end], ha='left', va='top')\n",
    "#     ax[col].invert_yaxis()\n",
    "#     ax[col].set_xlim(0, 2000)\n",
    "#     yax = ax[col].get_yaxis()\n",
    "#     yax.set_tick_params(pad=100)\n",
    "#     \n",
    "# plt.tight_layout\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T20:13:26.153663300Z",
     "start_time": "2024-12-08T20:13:26.135625400Z"
    }
   },
   "id": "8ed849cd7cdc3670"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a29bb2fb34eac5f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
